{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Problem Sheet\n",
    "\n",
    "Solutions to the Tensorflow Problem Sheet as part of Emerging Technologies Module - 4th Year Software Development\n",
    " \n",
    "#### Reference: https://github.com/emerging-technologies/keras-iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Use Tensorflow to create model\n",
    "\n",
    "#### Use Tensorflow to create a model to predict the species of Iris from a flower's sepal width, sepal length, petal width, and petal length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we get all needed imports and then load in the [Iris Dataset](https://github.com/mwaskom/seaborn-data/blob/master/iris.csv) into a list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adapted from: https://github.com/salmanahmad4u/keras-iris/blob/master/iris_nn.py\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "import keras as kr\n",
    "\n",
    "# Loading in the Iris dataset\n",
    "iris = list(csv.reader(open('iris.csv')))[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we want to split the dataset into float Arrays of Sepal Length, sepal width, petal length and petal with.\n",
    "<br>\n",
    "We do this using the 'Slicing' Technique. Slicing is is used when you want to seperate a list/array etc into sub-elements.\n",
    "<br>\n",
    "Reference: http://www.pythoncentral.io/how-to-slice-listsarrays-and-tuples-in-python/\n",
    "<br>\n",
    "\n",
    "Then where we have the outputs: Setosa, Versocolor or Virginica\n",
    "<br>\n",
    "We want to convert these strings into ints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The inputs are four floats\n",
    "inpts  = np.array(iris)[:,:4].astype(np.float)\n",
    "\n",
    "# Outputs are initially individual strings\n",
    "out = np.array(iris)[:,4]\n",
    "# Converting the strings to ints.\n",
    "out_vals, out_ints = np.unique(out, return_inverse=True)\n",
    "# Encode the category integers as binary categorical vairables.\n",
    "out_cats = kr.utils.to_categorical(out_ints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Split the data into training and testing\n",
    "\n",
    "#### Split the data set into a training set and a testing set. You should investigate the best way to do this, and list any online references used in your notebook. If you wish to, you can write some code to randomly separate the data on the fly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now, we want to split the sets into Training and Test Subsets. These are created in order to train the model we will soon create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inds = np.random.permutation(len(inpts))\n",
    "train_inds, test_inds = np.array_split(inds, 2)\n",
    "in_train, out_train = inpts[train_inds], out_cats[train_inds]\n",
    "in_test,  out_test  = inpts[test_inds],  out_cats[test_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
